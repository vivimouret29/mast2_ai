{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objetif de ce tp va être de découvrir les fonctionnalités d'Elasticsearch et de Kibana afin de construire un premier tableau de bord qui va permettre d'explorer un nouveau jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch \n",
    "from elasticsearch import helpers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez les infos sur le cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création client pour se connecter au serveur Elasticsearch (qui tourne sur le Docker) \n",
    "es_client=Elasticsearch([{'host':'localhost','port':9200}])\n",
    "es_client.cluster.health()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init and Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Téléchargez ces données et importez les dans un dataframe avec pandas\n",
    "https://www.kaggle.com/roshansharma/sanfranciso-crime-dataset?select=Police_Department_Incidents_-_Previous_Year__2016_.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO lire le csv à l'aide de pandas\n",
    "df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'index vide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "\n",
    "# TODO créer un index (vide pour l'instant) \"sf_crimes\" dans lequel on rajoutera les données\n",
    "# utiliser indices.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Visualisation des settings de l'index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO On affiche le mapping de l'index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de l'api helpers.bulk insérez tout le dataframe dans l'index que l'on vient de créer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(http_compress=True)\n",
    "\n",
    "\n",
    "def filterKeys(document, columns):\n",
    "    return {key: document[key] for key in columns }\n",
    "\n",
    "# TODO : remplacez les \"?\"\n",
    "# on utilise ici un générateur pour rajouter les documents à l'index\n",
    "def doc_generator(df, INDEX):\n",
    "    df_iter = df.iterrows()\n",
    "    for index, document in df_iter:\n",
    "        yield {\n",
    "                \"_index\": ??,\n",
    "                \"_type\": \"_doc\",\n",
    "                \"_id\" : f\"{??}\",\n",
    "                \"_source\": filterKeys(??, ??),\n",
    "            }\n",
    "    raise StopIteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisation de l'api bulk pour rakouter plusieurs documents au même temps\n",
    "helpers.bulk(es_client, doc_generator(df ,INDEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ca plante car nous n'avions pas géré les nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.where(df.notna(), lambda x: [None]) #Ici on permet à json de comprendre que c'est un Nan avec None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme on a inséré à partir des indexs, nous ne sommes pas obligés de tout supprimer. Le Bulk va réécrire et donc ne pas modifier ce qui existe déjà en base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.bulk(es_client, doc_generator(df_cleaned ,INDEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vérifie l'insert\n",
    "es.indices.refresh(INDEX)\n",
    "es.cat.count(INDEX, params={\"format\": \"json\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.refresh(INDEX)\n",
    "\n",
    "#TODO On affiche le mapping dynamique utilisé par défault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut s'apercevoir que le mapping par défaut n'est pas judicieux. Effectivement la date n'est pas traîtée comme telle. Il existe pour X et Y un type geopoint. \n",
    "Il va donc nous falloir créer un mapping et réinsérer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On ajoute un mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date\n",
    "Ajoutez un mapping pour prendre en compte les dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client.indices.delete(INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour les dates se baser sur : https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Créez un dict python qui contient le mapping que vous affectez dans la cellule suivante\n",
    "# format date : M/d/yyyy K:m:s a\n",
    "# type pour coord gps : geo_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client.indices.create(index=INDEX, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Affichez le mapping et vérifiez "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "helpers.bulk(es_client, doc_generator(_df_cleaned.head(1) ,INDEX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geopoint\n",
    "https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-point.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Faites de même que ce tuto pour pouvoir traîter Localisation comme un Geopoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kibana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de l'index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que les données sont bien formées, vous devez ajouter l'index sf_crimes à Kibana.\n",
    "Pour ce faire allez sur http://localhost:5601/ et cliquez à gauche sur \"Stack Management\" puis Index pattern et ajoutez sf_crimes*.\n",
    "Vérifiez dans la fenêtre suivante que le mapping est bon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une première visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant vous allez pouvoir commencer à créer plusieurs visualisations que vous rassemblerez dans un dashboard. On va commencer ma créer une carte qui géolocalise les crimes.\n",
    "Pour cela cliquez sur Visualize puis new. Je vous laisse chercher ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création d'un dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que vous avez plusieurs visualisations, vous pouvez vous créer un dashboard en ajoutant dans un nouveau dashboard les visualisations que vous avez préalablement sauvegardé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonne exploration :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
