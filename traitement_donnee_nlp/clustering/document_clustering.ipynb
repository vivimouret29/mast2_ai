{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb07a75",
   "metadata": {},
   "source": [
    "On possède un dataset de tweets, et on cherche à faire du clustering pour identifier les tweets parlant de sujets similaires.\n",
    "\n",
    "Pour ce TP, je ne vous ai passé qu'une partie du dataset. Si votre solution marche bien, ou que vous avez besoin de plus de données, et que vous avez un meilleur pc que moi,\n",
    "vous pouvez récupérer le reste du dataset ici :\n",
    "    \n",
    "https://github.com/fivethirtyeight/russian-troll-tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_file_1 = Path(\"IRAhandle_tweets_1.txt\")\n",
    "df = pd.read_csv(dataset_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7302b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = df[\"content\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Si vous n'avez pas déjà un word2vec entrainé : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "model.fill_norms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2145ed",
   "metadata": {},
   "source": [
    "# Comment utiliser une représentation des mots pour faire du clustering de phrase ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8abeba",
   "metadata": {},
   "source": [
    "- Solution 1 : obtenir la representation d'un mot, puis faire votre propre representation du tweet à partir de celle la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46d44a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v1 = model.get_vector(\"Bordeaux\")\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6004e",
   "metadata": {},
   "source": [
    "- Solution 2 : utiliser la méthode fournie pour comparer directement deux ensembles de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_similarity([\"I\", \"tweet\"],[\"I\",\"use\",\"twitter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_similarity([\"I\", \"tweet\"],[\"I\",\"use\",\"facebook\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03dc8b7",
   "metadata": {},
   "source": [
    "- Solution 3 : doc2vec ou autre embedding de phrases/documents plus élaborés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df818e7",
   "metadata": {},
   "source": [
    "### A partir du jeu de donnée, effectuer un clustering des tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c5ffd",
   "metadata": {},
   "source": [
    "Nettoyez votre jeu de données rapidement :\n",
    "\n",
    "    - ne gardez que 1000 phrase pour l'instant (surtout si votre pc est lent !)\n",
    "    - tokenizez chaque phrase\n",
    "    - enlevez les stops words et les mots non connus par votre model pré-entrainé (non présents dans valid_tokens ci dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords  \n",
    "  \n",
    "valid_tokens = set(model.key_to_index.keys())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nb_sentence = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469c18d",
   "metadata": {},
   "source": [
    "Créez une matrice de similarité :\n",
    "\n",
    "    - elle est de taille (nb_sentence, nb_sentence), ici (1000,1000)\n",
    "    - la case i,j indique la distance entre la phrase i et la phrase j, calculée au moyen de model.n_similarity\n",
    "    - pour l'algorithme de spectral clustering, elle doit valoir 1 si les phrases sont identiques, et 0 si les phrases sont completements différentes (ou une des phrase est vide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((nb_sentence, nb_sentence))\n",
    "\n",
    "# TODO : remplir la matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785dfe91",
   "metadata": {},
   "source": [
    "### Entrainons notre algorithme de clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855826c",
   "metadata": {},
   "source": [
    "- comme souvent en ML, une fois que l'on a fait le preprocessing adéquat, on a fait 80% du job !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "\n",
    "cls = SpectralClustering( affinity=\"precomputed\")\n",
    "preds = cls.fit_predict(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8791d0",
   "metadata": {},
   "source": [
    "### Visualisons tout ça"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44bf81",
   "metadata": {},
   "source": [
    "Avec une pca ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_as_array = np.zeros((nb_sentence, 68))\n",
    "for i, sen in enumerate(tokenized_sentences_int[:1000]):\n",
    "    data_as_array[i, :len(sen)] = sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67529338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tokenized_sentences_int \n",
    "transformed = PCA(n_components=2).fit_transform(data_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=transformed[:,0], y=transformed[:,1], c=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0bdb94",
   "metadata": {},
   "source": [
    "Regardons le contenu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.where(preds == 3)[0]:\n",
    "    print(tokenized_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e203f24",
   "metadata": {},
   "source": [
    " Le cluster à l'air de parler de Media et politique ?\n",
    " \n",
    " Comment améliorer :\n",
    "- plus de cluster\n",
    "- plus que 1000 exemples en train\n",
    "- semi-supervisés avec phrases d'exemples pour chaque cluster\n",
    "- meilleure métrique de distance (doc2vec, transformers, ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502df0d3",
   "metadata": {},
   "source": [
    "Question bonus : Pourquoi à votre avis je n'ai pas voulu utiliser l'algorithme de clustering DBSCAN ici ?\n",
    "- vous pouvez vérifier votre intuition en inversant la matrice de distance et en la fournissant à dbscan !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561bd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
