{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb07a75",
   "metadata": {},
   "source": [
    "On possède un dataset de tweets, et on cherche à faire du clustering pour identifier les tweets parlant de sujets similaires.\n",
    "\n",
    "Pour ce TP, je ne vous ai passé qu'une partie du dataset. Si votre solution marche bien, ou que vous avez besoin de plus de données, et que vous avez un meilleur pc que moi,\n",
    "vous pouvez récupérer le reste du dataset ici :\n",
    "    \n",
    "https://github.com/fivethirtyeight/russian-troll-tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86df541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_file_1 = Path(\"IRAhandle_tweets_1.txt\")\n",
    "df = pd.read_csv(dataset_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d7302b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = df[\"content\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae62d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"We have a sitting Democrat US Senator on trial for corruption and you\\'ve barely heard a peep from the mainstream media.\" ~ @nedryun https://t.co/gh6g0D1oiC',\n",
       "       'Marshawn Lynch arrives to game in anti-Trump shirt. Judging by his sagging pants the shirt should say Lynch vs. belt https://t.co/mLH1i30LZZ',\n",
       "       'Daughter of fallen Navy Sailor delivers powerful monologue on anthem protests, burns her NFL packers gear.  #BoycottNFL https://t.co/qDlFBGMeag',\n",
       "       ...,\n",
       "       'How we can rebuild trust in a UK divided by inequality and suspicion https://t.co/cz5y1r9ikh',\n",
       "       'John Humphrys accused of patronising Angela Rayner on Today programme https://t.co/1nWj11h0tR',\n",
       "       \"Fossilized poop found in 180-million-year-old 'ghost-gut' reveals a dinosaur's last meal https://t.co/BF6bsG3z39\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2735000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Si vous n'avez pas déjà un word2vec entrainé : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "model.fill_norms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2145ed",
   "metadata": {},
   "source": [
    "# Comment utiliser une représentation des mots pour faire du clustering de phrase ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8abeba",
   "metadata": {},
   "source": [
    "- Solution 1 : obtenir la representation d'un mot, puis faire votre propre representation du tweet à partir de celle la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd46d44a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [-4.29687500e-02 -2.12402344e-02 -3.07617188e-02  2.15820312e-01\n",
      "  4.14062500e-01  1.89453125e-01 -1.41601562e-01 -2.07031250e-01\n",
      "  2.94189453e-02  2.34375000e-01  3.03955078e-02  1.34765625e-01\n",
      "  2.24609375e-01 -2.57812500e-01 -1.15234375e-01  3.12500000e-01\n",
      " -9.03320312e-02  1.87500000e-01  2.69775391e-02  2.79296875e-01\n",
      "  1.80664062e-02 -2.09960938e-01  5.63964844e-02 -3.29589844e-02\n",
      " -2.82287598e-03  3.41796875e-01  1.59912109e-02 -1.20605469e-01\n",
      " -7.37304688e-02  1.33789062e-01 -5.63964844e-02  2.25585938e-01\n",
      " -2.81250000e-01 -9.17968750e-02 -1.34765625e-01  8.25195312e-02\n",
      " -4.37011719e-02 -1.90429688e-01 -1.30859375e-01 -4.47265625e-01\n",
      " -2.07031250e-01  1.50390625e-01  5.63964844e-02  1.95312500e-01\n",
      "  2.45117188e-01  3.95507812e-02  3.37890625e-01  5.63964844e-02\n",
      " -2.51953125e-01  9.46044922e-03 -4.17968750e-01  9.76562500e-02\n",
      " -4.78515625e-01 -5.83496094e-02 -5.58593750e-01  2.94921875e-01\n",
      " -3.71093750e-01  3.14941406e-02 -6.64062500e-02 -2.27539062e-01\n",
      " -2.98828125e-01  2.79296875e-01 -2.79296875e-01 -2.36328125e-01\n",
      " -3.61328125e-01 -2.33398438e-01 -1.89208984e-02 -3.51562500e-01\n",
      "  4.19921875e-01  1.36718750e-01 -5.00488281e-02  4.58984375e-02\n",
      "  2.24609375e-01 -1.34765625e-01 -1.44653320e-02  2.47070312e-01\n",
      "  8.05664062e-02 -3.41796875e-01 -1.57226562e-01 -1.79443359e-02\n",
      " -2.87109375e-01 -3.55468750e-01 -3.75976562e-02 -7.91015625e-02\n",
      "  1.99218750e-01  1.41601562e-01 -1.07910156e-01  1.94335938e-01\n",
      " -9.76562500e-02  9.33837891e-03 -1.51367188e-01 -1.09375000e-01\n",
      " -8.93554688e-02  3.54003906e-02 -1.81640625e-01 -1.74804688e-01\n",
      " -6.64062500e-02 -3.67187500e-01 -2.96875000e-01 -1.31835938e-01\n",
      " -2.63671875e-01 -2.31445312e-01 -2.23632812e-01  1.83593750e-01\n",
      "  1.26953125e-01 -5.73730469e-02  1.16210938e-01 -1.22070312e-01\n",
      " -3.24707031e-02 -2.05078125e-01  4.90722656e-02  7.95898438e-02\n",
      "  3.59375000e-01 -2.08984375e-01 -7.66601562e-02  1.31835938e-01\n",
      " -9.52148438e-03  2.36816406e-02  1.07421875e-01  1.25976562e-01\n",
      " -1.10839844e-01  1.49414062e-01  3.02734375e-02 -6.07910156e-02\n",
      "  5.00000000e-01 -1.78710938e-01 -1.42578125e-01 -3.68652344e-02\n",
      " -6.73828125e-02  1.49536133e-03 -1.74560547e-02  2.83203125e-02\n",
      " -2.02148438e-01 -2.23632812e-01  1.79687500e-01  1.43432617e-02\n",
      "  6.83593750e-02  3.43750000e-01  9.33837891e-03 -3.05175781e-02\n",
      "  2.09960938e-01 -3.24218750e-01 -9.42382812e-02 -3.55468750e-01\n",
      "  1.38671875e-01  2.75390625e-01  3.56445312e-02 -7.81250000e-02\n",
      " -8.05664062e-02 -4.02343750e-01  1.67236328e-02  1.97265625e-01\n",
      " -3.78417969e-02  1.21582031e-01  2.85156250e-01 -1.33789062e-01\n",
      "  5.49316406e-03  3.14941406e-02 -2.50000000e-01  2.31933594e-02\n",
      "  1.42578125e-01  2.13867188e-01  1.55273438e-01  4.95605469e-02\n",
      "  3.43750000e-01 -1.74560547e-02  1.25976562e-01  2.23632812e-01\n",
      " -5.83496094e-02  1.66992188e-01 -2.26562500e-01  1.12792969e-01\n",
      " -1.08886719e-01 -1.33789062e-01  5.73730469e-02 -2.11181641e-02\n",
      " -1.03515625e-01 -2.98828125e-01 -7.81250000e-02 -1.06445312e-01\n",
      "  1.03027344e-01  8.64257812e-02 -1.15722656e-01 -1.47094727e-02\n",
      "  2.85156250e-01 -2.39257812e-02  7.71484375e-02  3.12500000e-01\n",
      " -1.69921875e-01  5.51757812e-02  6.39648438e-02  1.21093750e-01\n",
      "  1.05957031e-01  1.05957031e-01  1.17187500e-02  2.38281250e-01\n",
      "  1.29882812e-01  1.01074219e-01 -1.72119141e-02 -6.04987144e-06\n",
      "  7.42187500e-02 -6.78710938e-02  8.64257812e-02 -2.04101562e-01\n",
      "  2.31445312e-01  4.32128906e-02  6.44531250e-02 -2.65625000e-01\n",
      "  2.16064453e-02 -1.42578125e-01 -4.88281250e-01  7.56835938e-02\n",
      " -3.02734375e-01  3.57421875e-01 -3.82812500e-01 -7.69042969e-03\n",
      " -1.55639648e-02 -1.60156250e-01  7.42187500e-02  2.22656250e-01\n",
      "  2.51953125e-01 -1.26953125e-01 -6.73828125e-02 -4.32128906e-02\n",
      "  1.37695312e-01  2.87109375e-01  4.47265625e-01  5.76171875e-02\n",
      "  2.32421875e-01  2.38281250e-01 -8.64257812e-02 -1.06445312e-01\n",
      " -5.10253906e-02  2.43164062e-01 -3.75000000e-01 -2.53906250e-01\n",
      " -1.99218750e-01  8.78906250e-02  4.12597656e-02  8.25195312e-02\n",
      "  3.02734375e-01 -1.34765625e-01  1.62109375e-01  1.27929688e-01\n",
      " -6.93359375e-02  1.60156250e-01 -1.10351562e-01 -2.53906250e-01\n",
      " -4.17968750e-01 -1.87500000e-01  9.52148438e-03  3.49121094e-02\n",
      " -6.29882812e-02  2.83203125e-01  1.04370117e-02  1.25000000e-01\n",
      " -2.35351562e-01  1.22558594e-01 -4.15039062e-02  1.97265625e-01\n",
      "  9.86328125e-02  4.44335938e-02  7.17773438e-02  2.49023438e-01\n",
      "  2.14843750e-01 -1.88476562e-01 -3.51562500e-01 -4.98046875e-01\n",
      " -1.89453125e-01 -1.25000000e-01 -2.13623047e-02  1.51367188e-01\n",
      " -1.11328125e-01  2.18750000e-01  1.82617188e-01  2.40478516e-02\n",
      "  8.05664062e-02  2.73437500e-02 -2.38281250e-01  3.00781250e-01\n",
      " -4.04296875e-01 -1.39648438e-01  2.36328125e-01  5.12695312e-02\n",
      " -1.21582031e-01  4.43359375e-01 -7.42187500e-02  9.17968750e-02\n",
      " -2.46093750e-01 -7.36236572e-04  1.96289062e-01  2.77343750e-01\n",
      "  2.15530396e-04  9.47265625e-02 -5.71289062e-02  5.51757812e-02\n",
      " -2.95410156e-02 -3.46679688e-02  1.75781250e-01  2.38281250e-01]\n"
     ]
    }
   ],
   "source": [
    "v1 = model.get_vector(\"Bordeaux\")\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6004e",
   "metadata": {},
   "source": [
    "- Solution 2 : utiliser la méthode fournie pour comparer directement deux ensembles de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bfc8e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098895"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity([\"I\", \"tweet\"],[\"I\",\"use\",\"twitter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef1f8066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69237375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity([\"I\", \"tweet\"],[\"I\",\"use\",\"facebook\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03dc8b7",
   "metadata": {},
   "source": [
    "- Solution 3 : doc2vec ou autre embedding de phrases/documents plus élaborés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df818e7",
   "metadata": {},
   "source": [
    "### A partir du jeu de donnée, effectuer un clustering des tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c5ffd",
   "metadata": {},
   "source": [
    "Nettoyez votre jeu de données rapidement :\n",
    "\n",
    "    - ne gardez que 1000 phrase pour l'instant (surtout si votre pc est lent !)\n",
    "    - tokenizez chaque phrase\n",
    "    - enlevez les stops words et les mots non connus par votre model pré-entrainé (non présents dans valid_tokens ci dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9b3e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords  \n",
    "  \n",
    "valid_tokens = set(model.key_to_index.keys())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nb_sentence = 1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73f3dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1998.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'We',\n",
       " 'sitting',\n",
       " 'Democrat',\n",
       " 'US',\n",
       " 'Senator',\n",
       " 'trial',\n",
       " 'corruption',\n",
       " \"'ve\",\n",
       " 'barely',\n",
       " 'heard',\n",
       " 'peep',\n",
       " 'mainstream',\n",
       " 'media',\n",
       " '.',\n",
       " \"''\",\n",
       " '~',\n",
       " '@',\n",
       " 'nedryun',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/gh6g0D1oiC']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(tweet: str) -> str:\n",
    "    tokens = word_tokenize(tweet)\n",
    "    tokens = [tk for tk in tokens if tk not in stop_words and tk.isalpha()]\n",
    "    return str(\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8721204f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_sentences \u001b[39m=\u001b[39m tweets_list[:nb_sentence]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;00m x: tokenize(x))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "valid_nd_stop =  [tk for tk in valid_tokens if tk in valid_tokens]\n",
    "tokenized_sentences = tweets_list[:nb_sentence].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469c18d",
   "metadata": {},
   "source": [
    "Créez une matrice de similarité :\n",
    "\n",
    "    - elle est de taille (nb_sentence, nb_sentence), ici (1000,1000)\n",
    "    - la case i,j indique la distance entre la phrase i et la phrase j, calculée au moyen de model.n_similarity\n",
    "    - pour l'algorithme de spectral clustering, elle doit valoir 1 si les phrases sont identiques, et 0 si les phrases sont completements différentes (ou une des phrase est vide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((nb_sentence, nb_sentence))\n",
    "\n",
    "# TODO : remplir la matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785dfe91",
   "metadata": {},
   "source": [
    "### Entrainons notre algorithme de clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855826c",
   "metadata": {},
   "source": [
    "- comme souvent en ML, une fois que l'on a fait le preprocessing adéquat, on a fait 80% du job !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "\n",
    "cls = SpectralClustering( affinity=\"precomputed\")\n",
    "preds = cls.fit_predict(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8791d0",
   "metadata": {},
   "source": [
    "### Visualisons tout ça"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44bf81",
   "metadata": {},
   "source": [
    "Avec une pca ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_as_array = np.zeros((nb_sentence, 68))\n",
    "for i, sen in enumerate(tokenized_sentences_int[:1000]):\n",
    "    data_as_array[i, :len(sen)] = sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67529338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tokenized_sentences_int \n",
    "transformed = PCA(n_components=2).fit_transform(data_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=transformed[:,0], y=transformed[:,1], c=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0bdb94",
   "metadata": {},
   "source": [
    "Regardons le contenu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.where(preds == 3)[0]:\n",
    "    print(tokenized_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e203f24",
   "metadata": {},
   "source": [
    " Le cluster à l'air de parler de Media et politique ?\n",
    " \n",
    " Comment améliorer :\n",
    "- plus de cluster\n",
    "- plus que 1000 exemples en train\n",
    "- semi-supervisés avec phrases d'exemples pour chaque cluster\n",
    "- meilleure métrique de distance (doc2vec, transformers, ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502df0d3",
   "metadata": {},
   "source": [
    "Question bonus : Pourquoi à votre avis je n'ai pas voulu utiliser l'algorithme de clustering DBSCAN ici ?\n",
    "- vous pouvez vérifier votre intuition en inversant la matrice de distance et en la fournissant à dbscan !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561bd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c389b737bcd67ac2381d1e99405763f0fb7777e2cb9e19f478e1ab531074b49b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
