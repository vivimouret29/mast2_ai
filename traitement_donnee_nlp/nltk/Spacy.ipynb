{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NLTK : bibliothèque basée sur l'analyse de chaine de caractère\n",
    "- Spacy : basée sur du langage objet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dans Nltk (en un peu moins simple), on dispose d'un moyen de telecharger les informations necessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in c:\\users\\pierre.leroy\\appdata\\local\\continuum\\miniconda3\\envs\\nlp\\lib\\site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Error: Couldn't link model to 'en_core_web_sm'\u001b[0m\n",
      "    Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "    permissions and try re-running the command as admin, or use a\n",
      "    virtualenv. You can still import the model as a module and call its\n",
      "    load() method, or create the symlink manually.\n",
      "\n",
      "    C:\\Users\\pierre.leroy\\AppData\\Local\\Continuum\\miniconda3\\envs\\nlp\\lib\\site-packages\\en_core_web_sm\n",
      "    -->\n",
      "    C:\\Users\\pierre.leroy\\AppData\\Local\\Continuum\\miniconda3\\envs\\nlp\\lib\\site-packages\\spacy\\data\\en_core_web_sm\n",
      "\n",
      "\n",
      "\u001b[93m    Creating a shortcut link for 'en' didn't work (maybe you don't have\n",
      "    admin permissions?), but you can still load the model via its full\n",
      "    package name: nlp = spacy.load('{name}')\u001b[0m\n",
      "    Download successful but linking failed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr_core_news_sm==2.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz (39.8MB)\n",
      "Building wheels for collected packages: fr-core-news-sm\n",
      "  Building wheel for fr-core-news-sm (setup.py): started\n",
      "  Building wheel for fr-core-news-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.0.0-cp36-none-any.whl size=39841461 sha256=504b9c99c59c47c590812de617558d893eeca391406d56758ed433ca49c52a0f\n",
      "  Stored in directory: C:\\Users\\PIERRE~1.LER\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-vtskquah\\wheels\\50\\cb\\17\\4b4c5a59786e77f375913b22b395922d768b069b7d7aa7bd24\n",
      "Successfully built fr-core-news-sm\n",
      "Installing collected packages: fr-core-news-sm\n",
      "  Found existing installation: fr-core-news-sm 2.3.0\n",
      "    Uninstalling fr-core-news-sm-2.3.0:\n",
      "      Successfully uninstalled fr-core-news-sm-2.3.0\n",
      "Successfully installed fr-core-news-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Error: Couldn't link model to 'fr_core_news_sm'\u001b[0m\n",
      "    Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "    permissions and try re-running the command as admin, or use a\n",
      "    virtualenv. You can still import the model as a module and call its\n",
      "    load() method, or create the symlink manually.\n",
      "\n",
      "    C:\\Users\\pierre.leroy\\AppData\\Local\\Continuum\\miniconda3\\envs\\nlp\\lib\\site-packages\\fr_core_news_sm\n",
      "    -->\n",
      "    C:\\Users\\pierre.leroy\\AppData\\Local\\Continuum\\miniconda3\\envs\\nlp\\lib\\site-packages\\spacy\\data\\fr_core_news_sm\n",
      "\n",
      "\n",
      "\u001b[93m    Creating a shortcut link for 'en' didn't work (maybe you don't have\n",
      "    admin permissions?), but you can still load the model via its full\n",
      "    package name: nlp = spacy.load('{name}')\u001b[0m\n",
      "    Download successful but linking failed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download fr_core_news_sm\n",
    "nlp_fr = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on peut trouver differentes versions de differentes tailles : sm/md/lg\n",
    "- on peut trouver une version utilisant du deep learning (transformers), tfr -mais il vous faudra telecharger 500mb de modeles + spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"And in early 2016, hackers at AnonSec claimed to have developed a method for gaining \\\n",
    "partial control over one of the Global Hawk drones used by NASA. Meanwhile, researchers at \\\n",
    "the Singapore University of Technology and Design have devised a technique for using drones \\\n",
    "to orchestrate MitM attacks which exploit wireless printing networks on a corporate scale, \\\n",
    "to eavesdrop on print jobs. The Flip Side: Counter-attack\\\\nAs with so many potential attack\\\n",
    "vectors, unmanned aerial vehicles may feature as a weapon in the armory of both defenders \\\n",
    "and attackers.For instance, the MalDrone backdoor malware kit has been developed as a \\\n",
    "universal hack, applicable to all makes and models of UAV.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization 'façon nltk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "tk = Tokenizer(nlp.vocab)\n",
    "tokens = tk(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And\n",
      "in\n",
      "early\n",
      "2016,\n",
      "hackers\n",
      "at\n",
      "AnonSec\n",
      "claimed\n",
      "to\n",
      "have\n",
      "developed\n",
      "a\n",
      "method\n",
      "for\n",
      "gaining\n",
      "partial\n",
      "control\n",
      "over\n",
      "one\n",
      "of\n",
      "the\n",
      "Global\n",
      "Hawk\n",
      "drones\n",
      "used\n",
      "by\n",
      "NASA.\n",
      "Meanwhile,\n",
      "researchers\n",
      "at\n",
      "the\n",
      "Singapore\n",
      "University\n",
      "of\n",
      "Technology\n",
      "and\n",
      "Design\n",
      "have\n",
      "devised\n",
      "a\n",
      "technique\n",
      "for\n",
      "using\n",
      "drones\n",
      "to\n",
      "orchestrate\n",
      "MitM\n",
      "attacks\n",
      "which\n",
      "exploit\n",
      "wireless\n",
      "printing\n",
      "networks\n",
      "on\n",
      "a\n",
      "corporate\n",
      "scale,\n",
      "to\n",
      "eavesdrop\n",
      "on\n",
      "print\n",
      "jobs.\n",
      "The\n",
      "Flip\n",
      "Side:\n",
      "Counter-attack\\nAs\n",
      "with\n",
      "so\n",
      "many\n",
      "potential\n",
      "attackvectors,\n",
      "unmanned\n",
      "aerial\n",
      "vehicles\n",
      "may\n",
      "feature\n",
      "as\n",
      "a\n",
      "weapon\n",
      "in\n",
      "the\n",
      "armory\n",
      "of\n",
      "both\n",
      "defenders\n",
      "and\n",
      "attackers.For\n",
      "instance,\n",
      "the\n",
      "MalDrone\n",
      "backdoor\n",
      "malware\n",
      "kit\n",
      "has\n",
      "been\n",
      "developed\n",
      "as\n",
      "a\n",
      "universal\n",
      "hack,\n",
      "applicable\n",
      "to\n",
      "all\n",
      "makes\n",
      "and\n",
      "models\n",
      "of\n",
      "UAV.\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- les mêmes erreurs que nltk !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization \"façon spacy\" \n",
    "- que je recommande car permet facilement de faire les autre étapes nlp classique\n",
    "- plus courte en nombre de ligne de code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And <class 'spacy.tokens.token.Token'>\n",
      "in <class 'spacy.tokens.token.Token'>\n",
      "early <class 'spacy.tokens.token.Token'>\n",
      "2016 <class 'spacy.tokens.token.Token'>\n",
      ", <class 'spacy.tokens.token.Token'>\n",
      "hackers <class 'spacy.tokens.token.Token'>\n",
      "at <class 'spacy.tokens.token.Token'>\n",
      "AnonSec <class 'spacy.tokens.token.Token'>\n",
      "claimed <class 'spacy.tokens.token.Token'>\n",
      "to <class 'spacy.tokens.token.Token'>\n",
      "have <class 'spacy.tokens.token.Token'>\n",
      "developed <class 'spacy.tokens.token.Token'>\n",
      "a <class 'spacy.tokens.token.Token'>\n",
      "method <class 'spacy.tokens.token.Token'>\n",
      "for <class 'spacy.tokens.token.Token'>\n",
      "gaining <class 'spacy.tokens.token.Token'>\n",
      "partial <class 'spacy.tokens.token.Token'>\n",
      "control <class 'spacy.tokens.token.Token'>\n",
      "over <class 'spacy.tokens.token.Token'>\n",
      "one <class 'spacy.tokens.token.Token'>\n",
      "of <class 'spacy.tokens.token.Token'>\n",
      "the <class 'spacy.tokens.token.Token'>\n",
      "Global <class 'spacy.tokens.token.Token'>\n",
      "Hawk <class 'spacy.tokens.token.Token'>\n",
      "drones <class 'spacy.tokens.token.Token'>\n",
      "used <class 'spacy.tokens.token.Token'>\n",
      "by <class 'spacy.tokens.token.Token'>\n",
      "NASA <class 'spacy.tokens.token.Token'>\n",
      ". <class 'spacy.tokens.token.Token'>\n",
      "Meanwhile <class 'spacy.tokens.token.Token'>\n",
      ", <class 'spacy.tokens.token.Token'>\n",
      "researchers <class 'spacy.tokens.token.Token'>\n",
      "at <class 'spacy.tokens.token.Token'>\n",
      "the <class 'spacy.tokens.token.Token'>\n",
      "Singapore <class 'spacy.tokens.token.Token'>\n",
      "University <class 'spacy.tokens.token.Token'>\n",
      "of <class 'spacy.tokens.token.Token'>\n",
      "Technology <class 'spacy.tokens.token.Token'>\n",
      "and <class 'spacy.tokens.token.Token'>\n",
      "Design <class 'spacy.tokens.token.Token'>\n",
      "have <class 'spacy.tokens.token.Token'>\n",
      "devised <class 'spacy.tokens.token.Token'>\n",
      "a <class 'spacy.tokens.token.Token'>\n",
      "technique <class 'spacy.tokens.token.Token'>\n",
      "for <class 'spacy.tokens.token.Token'>\n",
      "using <class 'spacy.tokens.token.Token'>\n",
      "drones <class 'spacy.tokens.token.Token'>\n",
      "to <class 'spacy.tokens.token.Token'>\n",
      "orchestrate <class 'spacy.tokens.token.Token'>\n",
      "MitM <class 'spacy.tokens.token.Token'>\n",
      "attacks <class 'spacy.tokens.token.Token'>\n",
      "which <class 'spacy.tokens.token.Token'>\n",
      "exploit <class 'spacy.tokens.token.Token'>\n",
      "wireless <class 'spacy.tokens.token.Token'>\n",
      "printing <class 'spacy.tokens.token.Token'>\n",
      "networks <class 'spacy.tokens.token.Token'>\n",
      "on <class 'spacy.tokens.token.Token'>\n",
      "a <class 'spacy.tokens.token.Token'>\n",
      "corporate <class 'spacy.tokens.token.Token'>\n",
      "scale <class 'spacy.tokens.token.Token'>\n",
      ", <class 'spacy.tokens.token.Token'>\n",
      "to <class 'spacy.tokens.token.Token'>\n",
      "eavesdrop <class 'spacy.tokens.token.Token'>\n",
      "on <class 'spacy.tokens.token.Token'>\n",
      "print <class 'spacy.tokens.token.Token'>\n",
      "jobs <class 'spacy.tokens.token.Token'>\n",
      ". <class 'spacy.tokens.token.Token'>\n",
      "The <class 'spacy.tokens.token.Token'>\n",
      "Flip <class 'spacy.tokens.token.Token'>\n",
      "Side <class 'spacy.tokens.token.Token'>\n",
      ": <class 'spacy.tokens.token.Token'>\n",
      "Counter <class 'spacy.tokens.token.Token'>\n",
      "- <class 'spacy.tokens.token.Token'>\n",
      "attack\\nAs <class 'spacy.tokens.token.Token'>\n",
      "with <class 'spacy.tokens.token.Token'>\n",
      "so <class 'spacy.tokens.token.Token'>\n",
      "many <class 'spacy.tokens.token.Token'>\n",
      "potential <class 'spacy.tokens.token.Token'>\n",
      "attackvectors <class 'spacy.tokens.token.Token'>\n",
      ", <class 'spacy.tokens.token.Token'>\n",
      "unmanned <class 'spacy.tokens.token.Token'>\n",
      "aerial <class 'spacy.tokens.token.Token'>\n",
      "vehicles <class 'spacy.tokens.token.Token'>\n",
      "may <class 'spacy.tokens.token.Token'>\n",
      "feature <class 'spacy.tokens.token.Token'>\n",
      "as <class 'spacy.tokens.token.Token'>\n",
      "a <class 'spacy.tokens.token.Token'>\n",
      "weapon <class 'spacy.tokens.token.Token'>\n",
      "in <class 'spacy.tokens.token.Token'>\n",
      "the <class 'spacy.tokens.token.Token'>\n",
      "armory <class 'spacy.tokens.token.Token'>\n",
      "of <class 'spacy.tokens.token.Token'>\n",
      "both <class 'spacy.tokens.token.Token'>\n",
      "defenders <class 'spacy.tokens.token.Token'>\n",
      "and <class 'spacy.tokens.token.Token'>\n",
      "attackers <class 'spacy.tokens.token.Token'>\n",
      ". <class 'spacy.tokens.token.Token'>\n",
      "For <class 'spacy.tokens.token.Token'>\n",
      "instance <class 'spacy.tokens.token.Token'>\n",
      ", <class 'spacy.tokens.token.Token'>\n",
      "the <class 'spacy.tokens.token.Token'>\n",
      "MalDrone <class 'spacy.tokens.token.Token'>\n",
      "backdoor <class 'spacy.tokens.token.Token'>\n",
      "malware <class 'spacy.tokens.token.Token'>\n",
      "kit <class 'spacy.tokens.token.Token'>\n",
      "has <class 'spacy.tokens.token.Token'>\n",
      "been <class 'spacy.tokens.token.Token'>\n",
      "developed <class 'spacy.tokens.token.Token'>\n",
      "as <class 'spacy.tokens.token.Token'>\n",
      "a <class 'spacy.tokens.token.Token'>\n",
      "universal <class 'spacy.tokens.token.Token'>\n",
      "hack <class 'spacy.tokens.token.Token'>\n",
      ", <class 'spacy.tokens.token.Token'>\n",
      "applicable <class 'spacy.tokens.token.Token'>\n",
      "to <class 'spacy.tokens.token.Token'>\n",
      "all <class 'spacy.tokens.token.Token'>\n",
      "makes <class 'spacy.tokens.token.Token'>\n",
      "and <class 'spacy.tokens.token.Token'>\n",
      "models <class 'spacy.tokens.token.Token'>\n",
      "of <class 'spacy.tokens.token.Token'>\n",
      "UAV <class 'spacy.tokens.token.Token'>\n",
      ". <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word,type(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'abord',\n",
       " 'absolument',\n",
       " 'afin',\n",
       " 'ah',\n",
       " 'ai',\n",
       " 'aie',\n",
       " 'ailleurs',\n",
       " 'ainsi',\n",
       " 'ait',\n",
       " 'allaient',\n",
       " 'allo',\n",
       " 'allons',\n",
       " 'allô',\n",
       " 'alors',\n",
       " 'anterieur',\n",
       " 'anterieure',\n",
       " 'anterieures',\n",
       " 'apres',\n",
       " 'après',\n",
       " 'as',\n",
       " 'assez',\n",
       " 'attendu',\n",
       " 'au',\n",
       " 'aucun',\n",
       " 'aucune',\n",
       " 'aujourd',\n",
       " \"aujourd'hui\",\n",
       " 'aupres',\n",
       " 'auquel',\n",
       " 'aura',\n",
       " 'auraient',\n",
       " 'aurait',\n",
       " 'auront',\n",
       " 'aussi',\n",
       " 'autre',\n",
       " 'autrefois',\n",
       " 'autrement',\n",
       " 'autres',\n",
       " 'autrui',\n",
       " 'aux',\n",
       " 'auxquelles',\n",
       " 'auxquels',\n",
       " 'avaient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avant',\n",
       " 'avec',\n",
       " 'avoir',\n",
       " 'avons',\n",
       " 'ayant',\n",
       " 'bah',\n",
       " 'bas',\n",
       " 'basee',\n",
       " 'bat',\n",
       " 'beau',\n",
       " 'beaucoup',\n",
       " 'bien',\n",
       " 'bigre',\n",
       " 'boum',\n",
       " 'bravo',\n",
       " 'brrr',\n",
       " \"c'\",\n",
       " 'car',\n",
       " 'ce',\n",
       " 'ceci',\n",
       " 'cela',\n",
       " 'celle',\n",
       " 'celle-ci',\n",
       " 'celle-là',\n",
       " 'celles',\n",
       " 'celles-ci',\n",
       " 'celles-là',\n",
       " 'celui',\n",
       " 'celui-ci',\n",
       " 'celui-là',\n",
       " 'cent',\n",
       " 'cependant',\n",
       " 'certain',\n",
       " 'certaine',\n",
       " 'certaines',\n",
       " 'certains',\n",
       " 'certes',\n",
       " 'ces',\n",
       " 'cet',\n",
       " 'cette',\n",
       " 'ceux',\n",
       " 'ceux-ci',\n",
       " 'ceux-là',\n",
       " 'chacun',\n",
       " 'chacune',\n",
       " 'chaque',\n",
       " 'cher',\n",
       " 'chers',\n",
       " 'chez',\n",
       " 'chiche',\n",
       " 'chut',\n",
       " 'chère',\n",
       " 'chères',\n",
       " 'ci',\n",
       " 'cinq',\n",
       " 'cinquantaine',\n",
       " 'cinquante',\n",
       " 'cinquantième',\n",
       " 'cinquième',\n",
       " 'clac',\n",
       " 'clic',\n",
       " 'combien',\n",
       " 'comme',\n",
       " 'comment',\n",
       " 'comparable',\n",
       " 'comparables',\n",
       " 'compris',\n",
       " 'concernant',\n",
       " 'contre',\n",
       " 'couic',\n",
       " 'crac',\n",
       " 'c’',\n",
       " \"d'\",\n",
       " 'da',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'debout',\n",
       " 'dedans',\n",
       " 'dehors',\n",
       " 'deja',\n",
       " 'delà',\n",
       " 'depuis',\n",
       " 'dernier',\n",
       " 'derniere',\n",
       " 'derriere',\n",
       " 'derrière',\n",
       " 'des',\n",
       " 'desormais',\n",
       " 'desquelles',\n",
       " 'desquels',\n",
       " 'dessous',\n",
       " 'dessus',\n",
       " 'deux',\n",
       " 'deuxième',\n",
       " 'deuxièmement',\n",
       " 'devant',\n",
       " 'devers',\n",
       " 'devra',\n",
       " 'different',\n",
       " 'differentes',\n",
       " 'differents',\n",
       " 'différent',\n",
       " 'différente',\n",
       " 'différentes',\n",
       " 'différents',\n",
       " 'dire',\n",
       " 'directe',\n",
       " 'directement',\n",
       " 'dit',\n",
       " 'dite',\n",
       " 'dits',\n",
       " 'divers',\n",
       " 'diverse',\n",
       " 'diverses',\n",
       " 'dix',\n",
       " 'dix-huit',\n",
       " 'dix-neuf',\n",
       " 'dix-sept',\n",
       " 'dixième',\n",
       " 'doit',\n",
       " 'doivent',\n",
       " 'donc',\n",
       " 'dont',\n",
       " 'douze',\n",
       " 'douzième',\n",
       " 'dring',\n",
       " 'du',\n",
       " 'duquel',\n",
       " 'durant',\n",
       " 'dès',\n",
       " 'désormais',\n",
       " 'd’',\n",
       " 'effet',\n",
       " 'egale',\n",
       " 'egalement',\n",
       " 'egales',\n",
       " 'eh',\n",
       " 'elle',\n",
       " 'elle-même',\n",
       " 'elles',\n",
       " 'elles-mêmes',\n",
       " 'en',\n",
       " 'encore',\n",
       " 'enfin',\n",
       " 'entre',\n",
       " 'envers',\n",
       " 'environ',\n",
       " 'es',\n",
       " 'est',\n",
       " 'et',\n",
       " 'etaient',\n",
       " 'etais',\n",
       " 'etait',\n",
       " 'etant',\n",
       " 'etc',\n",
       " 'etre',\n",
       " 'eu',\n",
       " 'euh',\n",
       " 'eux',\n",
       " 'eux-mêmes',\n",
       " 'exactement',\n",
       " 'excepté',\n",
       " 'extenso',\n",
       " 'exterieur',\n",
       " 'fais',\n",
       " 'faisaient',\n",
       " 'faisant',\n",
       " 'fait',\n",
       " 'façon',\n",
       " 'feront',\n",
       " 'fi',\n",
       " 'flac',\n",
       " 'floc',\n",
       " 'font',\n",
       " 'gens',\n",
       " 'ha',\n",
       " 'hein',\n",
       " 'hem',\n",
       " 'hep',\n",
       " 'hi',\n",
       " 'ho',\n",
       " 'holà',\n",
       " 'hop',\n",
       " 'hormis',\n",
       " 'hors',\n",
       " 'hou',\n",
       " 'houp',\n",
       " 'hue',\n",
       " 'hui',\n",
       " 'huit',\n",
       " 'huitième',\n",
       " 'hum',\n",
       " 'hurrah',\n",
       " 'hé',\n",
       " 'hélas',\n",
       " 'i',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'importe',\n",
       " \"j'\",\n",
       " 'je',\n",
       " 'jusqu',\n",
       " 'jusque',\n",
       " 'juste',\n",
       " 'j’',\n",
       " \"l'\",\n",
       " 'la',\n",
       " 'laisser',\n",
       " 'laquelle',\n",
       " 'las',\n",
       " 'le',\n",
       " 'lequel',\n",
       " 'les',\n",
       " 'lesquelles',\n",
       " 'lesquels',\n",
       " 'leur',\n",
       " 'leurs',\n",
       " 'longtemps',\n",
       " 'lors',\n",
       " 'lorsque',\n",
       " 'lui',\n",
       " 'lui-meme',\n",
       " 'lui-même',\n",
       " 'là',\n",
       " 'lès',\n",
       " 'l’',\n",
       " \"m'\",\n",
       " 'ma',\n",
       " 'maint',\n",
       " 'maintenant',\n",
       " 'mais',\n",
       " 'malgre',\n",
       " 'malgré',\n",
       " 'maximale',\n",
       " 'me',\n",
       " 'meme',\n",
       " 'memes',\n",
       " 'merci',\n",
       " 'mes',\n",
       " 'mien',\n",
       " 'mienne',\n",
       " 'miennes',\n",
       " 'miens',\n",
       " 'mille',\n",
       " 'mince',\n",
       " 'minimale',\n",
       " 'moi',\n",
       " 'moi-meme',\n",
       " 'moi-même',\n",
       " 'moindres',\n",
       " 'moins',\n",
       " 'mon',\n",
       " 'moyennant',\n",
       " 'multiple',\n",
       " 'multiples',\n",
       " 'même',\n",
       " 'mêmes',\n",
       " 'm’',\n",
       " \"n'\",\n",
       " 'na',\n",
       " 'naturel',\n",
       " 'naturelle',\n",
       " 'naturelles',\n",
       " 'ne',\n",
       " 'neanmoins',\n",
       " 'necessaire',\n",
       " 'necessairement',\n",
       " 'neuf',\n",
       " 'neuvième',\n",
       " 'ni',\n",
       " 'nombreuses',\n",
       " 'nombreux',\n",
       " 'non',\n",
       " 'nos',\n",
       " 'notamment',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'nous-mêmes',\n",
       " 'nouveau',\n",
       " 'nul',\n",
       " 'néanmoins',\n",
       " 'nôtre',\n",
       " 'nôtres',\n",
       " 'n’',\n",
       " 'o',\n",
       " 'oh',\n",
       " 'ohé',\n",
       " 'ollé',\n",
       " 'olé',\n",
       " 'on',\n",
       " 'ont',\n",
       " 'onze',\n",
       " 'onzième',\n",
       " 'ore',\n",
       " 'ou',\n",
       " 'ouf',\n",
       " 'ouias',\n",
       " 'oust',\n",
       " 'ouste',\n",
       " 'outre',\n",
       " 'ouvert',\n",
       " 'ouverte',\n",
       " 'ouverts',\n",
       " 'où',\n",
       " 'paf',\n",
       " 'pan',\n",
       " 'par',\n",
       " 'parce',\n",
       " 'parfois',\n",
       " 'parle',\n",
       " 'parlent',\n",
       " 'parler',\n",
       " 'parmi',\n",
       " 'parseme',\n",
       " 'partant',\n",
       " 'particulier',\n",
       " 'particulière',\n",
       " 'particulièrement',\n",
       " 'pas',\n",
       " 'passé',\n",
       " 'pendant',\n",
       " 'pense',\n",
       " 'permet',\n",
       " 'personne',\n",
       " 'peu',\n",
       " 'peut',\n",
       " 'peuvent',\n",
       " 'peux',\n",
       " 'pff',\n",
       " 'pfft',\n",
       " 'pfut',\n",
       " 'pif',\n",
       " 'pire',\n",
       " 'plein',\n",
       " 'plouf',\n",
       " 'plus',\n",
       " 'plusieurs',\n",
       " 'plutôt',\n",
       " 'possessif',\n",
       " 'possessifs',\n",
       " 'possible',\n",
       " 'possibles',\n",
       " 'pouah',\n",
       " 'pour',\n",
       " 'pourquoi',\n",
       " 'pourrais',\n",
       " 'pourrait',\n",
       " 'pouvait',\n",
       " 'prealable',\n",
       " 'precisement',\n",
       " 'premier',\n",
       " 'première',\n",
       " 'premièrement',\n",
       " 'pres',\n",
       " 'probable',\n",
       " 'probante',\n",
       " 'procedant',\n",
       " 'proche',\n",
       " 'près',\n",
       " 'psitt',\n",
       " 'pu',\n",
       " 'puis',\n",
       " 'puisque',\n",
       " 'pur',\n",
       " 'pure',\n",
       " \"qu'\",\n",
       " 'quand',\n",
       " 'quant',\n",
       " 'quant-à-soi',\n",
       " 'quanta',\n",
       " 'quarante',\n",
       " 'quatorze',\n",
       " 'quatre',\n",
       " 'quatre-vingt',\n",
       " 'quatrième',\n",
       " 'quatrièmement',\n",
       " 'que',\n",
       " 'quel',\n",
       " 'quelconque',\n",
       " 'quelle',\n",
       " 'quelles',\n",
       " \"quelqu'un\",\n",
       " 'quelque',\n",
       " 'quelques',\n",
       " 'quels',\n",
       " 'qui',\n",
       " 'quiconque',\n",
       " 'quinze',\n",
       " 'quoi',\n",
       " 'quoique',\n",
       " 'qu’',\n",
       " 'rare',\n",
       " 'rarement',\n",
       " 'rares',\n",
       " 'relative',\n",
       " 'relativement',\n",
       " 'remarquable',\n",
       " 'rend',\n",
       " 'rendre',\n",
       " 'restant',\n",
       " 'reste',\n",
       " 'restent',\n",
       " 'restrictif',\n",
       " 'retour',\n",
       " 'revoici',\n",
       " 'revoilà',\n",
       " 'rien',\n",
       " \"s'\",\n",
       " 'sa',\n",
       " 'sacrebleu',\n",
       " 'sait',\n",
       " 'sans',\n",
       " 'sapristi',\n",
       " 'sauf',\n",
       " 'se',\n",
       " 'sein',\n",
       " 'seize',\n",
       " 'selon',\n",
       " 'semblable',\n",
       " 'semblaient',\n",
       " 'semble',\n",
       " 'semblent',\n",
       " 'sent',\n",
       " 'sept',\n",
       " 'septième',\n",
       " 'sera',\n",
       " 'seraient',\n",
       " 'serait',\n",
       " 'seront',\n",
       " 'ses',\n",
       " 'seul',\n",
       " 'seule',\n",
       " 'seulement',\n",
       " 'si',\n",
       " 'sien',\n",
       " 'sienne',\n",
       " 'siennes',\n",
       " 'siens',\n",
       " 'sinon',\n",
       " 'six',\n",
       " 'sixième',\n",
       " 'soi',\n",
       " 'soi-même',\n",
       " 'soit',\n",
       " 'soixante',\n",
       " 'son',\n",
       " 'sont',\n",
       " 'sous',\n",
       " 'souvent',\n",
       " 'specifique',\n",
       " 'specifiques',\n",
       " 'speculatif',\n",
       " 'stop',\n",
       " 'strictement',\n",
       " 'subtiles',\n",
       " 'suffisant',\n",
       " 'suffisante',\n",
       " 'suffit',\n",
       " 'suis',\n",
       " 'suit',\n",
       " 'suivant',\n",
       " 'suivante',\n",
       " 'suivantes',\n",
       " 'suivants',\n",
       " 'suivre',\n",
       " 'superpose',\n",
       " 'sur',\n",
       " 'surtout',\n",
       " 's’',\n",
       " \"t'\",\n",
       " 'ta',\n",
       " 'tac',\n",
       " 'tant',\n",
       " 'tardive',\n",
       " 'te',\n",
       " 'tel',\n",
       " 'telle',\n",
       " 'tellement',\n",
       " 'telles',\n",
       " 'tels',\n",
       " 'tenant',\n",
       " 'tend',\n",
       " 'tenir',\n",
       " 'tente',\n",
       " 'tes',\n",
       " 'tic',\n",
       " 'tien',\n",
       " 'tienne',\n",
       " 'tiennes',\n",
       " 'tiens',\n",
       " 'toc',\n",
       " 'toi',\n",
       " 'toi-même',\n",
       " 'ton',\n",
       " 'touchant',\n",
       " 'toujours',\n",
       " 'tous',\n",
       " 'tout',\n",
       " 'toute',\n",
       " 'toutefois',\n",
       " 'toutes',\n",
       " 'treize',\n",
       " 'trente',\n",
       " 'tres',\n",
       " 'trois',\n",
       " 'troisième',\n",
       " 'troisièmement',\n",
       " 'trop',\n",
       " 'très',\n",
       " 'tsoin',\n",
       " 'tsouin',\n",
       " 'tu',\n",
       " 'té',\n",
       " 't’',\n",
       " 'un',\n",
       " 'une',\n",
       " 'unes',\n",
       " 'uniformement',\n",
       " 'unique',\n",
       " 'uniques',\n",
       " 'uns',\n",
       " 'va',\n",
       " 'vais',\n",
       " 'vas',\n",
       " 'vers',\n",
       " 'via',\n",
       " 'vif',\n",
       " 'vifs',\n",
       " 'vingt',\n",
       " 'vivat',\n",
       " 'vive',\n",
       " 'vives',\n",
       " 'vlan',\n",
       " 'voici',\n",
       " 'voilà',\n",
       " 'vont',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'vous-mêmes',\n",
       " 'vu',\n",
       " 'vé',\n",
       " 'vôtre',\n",
       " 'vôtres',\n",
       " 'zut',\n",
       " 'à',\n",
       " 'â',\n",
       " 'ça',\n",
       " 'ès',\n",
       " 'étaient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étant',\n",
       " 'été',\n",
       " 'être',\n",
       " 'ô'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_fr.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la façon de programmer de Spacy permet de passer facilement d'un langage a un autre avec le même code\n",
    "\n",
    "Comment enlever ces stops words ? éviter l'erreur \"classique\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[And, in, early, 2016,, hackers, at, AnonSec, claimed, to, have, developed, a, method, for, gaining, partial, control, over, one, of, the, Global, Hawk, drones, used, by, NASA., Meanwhile,, researchers, at, the, Singapore, University, of, Technology, and, Design, have, devised, a, technique, for, using, drones, to, orchestrate, MitM, attacks, which, exploit, wireless, printing, networks, on, a, corporate, scale,, to, eavesdrop, on, print, jobs., The, Flip, Side:, Counter-attack\\nAs, with, so, many, potential, attackvectors,, unmanned, aerial, vehicles, may, feature, as, a, weapon, in, the, armory, of, both, defenders, and, attackers.For, instance,, the, MalDrone, backdoor, malware, kit, has, been, developed, as, a, universal, hack,, applicable, to, all, makes, and, models, of, UAV.]\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [word for word in tokens if not word in nlp.Defaults.stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca n'a pas marché ?\n",
    "- Il ne faut pas oublier que spacy retourne usuellement des objets\n",
    "- ... qui ne supportent pas forcement la comparaison directe avec des strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(nlp.Defaults.stop_words)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token  a\n",
      "token in stop word  False\n",
      "str(token) in stop words True\n"
     ]
    }
   ],
   "source": [
    "print(\"token \",tokens[11])\n",
    "print(\"token in stop word \",tokens[11] in nlp.Defaults.stop_words)\n",
    "print(\"str(token) in stop words\", str(tokens[11]) in nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[And, early, 2016,, hackers, AnonSec, claimed, developed, method, gaining, partial, control, Global, Hawk, drones, NASA., Meanwhile,, researchers, Singapore, University, Technology, Design, devised, technique, drones, orchestrate, MitM, attacks, exploit, wireless, printing, networks, corporate, scale,, eavesdrop, print, jobs., The, Flip, Side:, Counter-attack\\nAs, potential, attackvectors,, unmanned, aerial, vehicles, feature, weapon, armory, defenders, attackers.For, instance,, MalDrone, backdoor, malware, kit, developed, universal, hack,, applicable, makes, models, UAV.]\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [word for word in tokens if not str(word) in nlp.Defaults.stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ca a bien le comportement attendu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEMMING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il n'y en a pas, utiliser NLTK dans ce cas\n",
    "- Spacy ne souhaitait pas dupliquer des fonctionalités déjà présentes dans d'autres modules à l'identiques\n",
    "- on prefere souvent la lemmatisation au stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2283656566040971221 and\n",
      "3002984154512732771 in\n",
      "1108542766809193907 early\n",
      "1451041761559935927 2016\n",
      "2593208677638477497 ,\n",
      "597684636259421448 hacker\n",
      "11667289587015813222 at\n",
      "9820377712562776304 anonsec\n",
      "4563812988814619444 claim\n",
      "3791531372978436496 to\n",
      "14692702688101715474 have\n",
      "16473443321107972938 develop\n",
      "11901859001352538922 a\n",
      "3449386869681536401 method\n",
      "16037325823156266367 for\n",
      "7762834187326165067 gain\n",
      "11387534614649667802 partial\n",
      "572204754761179701 control\n",
      "5456543204961066030 over\n",
      "17454115351911680600 one\n",
      "886050111519832510 of\n",
      "7425985699627899538 the\n",
      "17053192215331816304 global\n",
      "2345501420697115458 hawk\n",
      "3546477731327827945 drone\n",
      "6873750497785110593 use\n",
      "16764210730586636600 by\n",
      "11235406971919280924 nasa\n",
      "12646065887601541794 .\n",
      "8580937503330074383 meanwhile\n",
      "2593208677638477497 ,\n",
      "1317581537614213870 researcher\n",
      "11667289587015813222 at\n",
      "7425985699627899538 the\n",
      "10329536245932617809 singapore\n",
      "10576426701297570588 university\n",
      "886050111519832510 of\n",
      "1740049878576065363 technology\n",
      "2283656566040971221 and\n",
      "4105053907530138126 design\n",
      "14692702688101715474 have\n",
      "2758648503438371934 devise\n",
      "11901859001352538922 a\n",
      "4416460672513035679 technique\n",
      "16037325823156266367 for\n",
      "6873750497785110593 use\n",
      "3546477731327827945 drone\n",
      "3791531372978436496 to\n",
      "12457602659165797261 orchestrate\n",
      "13630260046104690905 mitm\n",
      "9652614884489271923 attack\n",
      "7063653163634019529 which\n",
      "6642153553068112355 exploit\n",
      "5324050387224737116 wireless\n",
      "4220070155260987654 print\n",
      "2515988597143367740 network\n",
      "5640369432778651323 on\n",
      "11901859001352538922 a\n",
      "13788650032919693367 corporate\n",
      "1800900351006314234 scale\n",
      "2593208677638477497 ,\n",
      "3791531372978436496 to\n",
      "7733341954640116723 eavesdrop\n",
      "5640369432778651323 on\n",
      "4220070155260987654 print\n",
      "18425606103329785088 job\n",
      "12646065887601541794 .\n",
      "7425985699627899538 the\n",
      "5542394297506187061 flip\n",
      "8664790716774201746 side\n",
      "11532473245541075862 :\n",
      "15043103400775822501 counter\n",
      "9153284864653046197 -\n",
      "1578596384931511169 attack\\nas\n",
      "12510949447758279278 with\n",
      "9781598966686434415 so\n",
      "9720044723474553187 many\n",
      "15822686403977818401 potential\n",
      "6162455773902923737 attackvector\n",
      "2593208677638477497 ,\n",
      "5440078163854359165 unmanned\n",
      "202141554292152643 aerial\n",
      "854351138829791262 vehicle\n",
      "14378475389916013800 may\n",
      "16417888112635110788 feature\n",
      "7437575085468336610 as\n",
      "11901859001352538922 a\n",
      "737483929102886782 weapon\n",
      "3002984154512732771 in\n",
      "7425985699627899538 the\n",
      "14896743564332281036 armory\n",
      "886050111519832510 of\n",
      "7111508780595485950 both\n",
      "12815351048287356561 defender\n",
      "2283656566040971221 and\n",
      "3842406329712751934 attacker\n",
      "12646065887601541794 .\n",
      "16037325823156266367 for\n",
      "12554794110057516407 instance\n",
      "2593208677638477497 ,\n",
      "7425985699627899538 the\n",
      "7233801041030849386 maldrone\n",
      "14708038087198172319 backdoor\n",
      "8239383364886273312 malware\n",
      "8956821967719294438 kit\n",
      "14692702688101715474 have\n",
      "10382539506755952630 be\n",
      "16473443321107972938 develop\n",
      "7437575085468336610 as\n",
      "11901859001352538922 a\n",
      "975422080830217475 universal\n",
      "16189445987676552916 hack\n",
      "2593208677638477497 ,\n",
      "15717441996292838248 applicable\n",
      "3791531372978436496 to\n",
      "13409319323822384369 all\n",
      "9614445426764226664 make\n",
      "2283656566040971221 and\n",
      "5265715978910192994 model\n",
      "886050111519832510 of\n",
      "9173437692297414213 uav\n",
      "12646065887601541794 .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.lemma, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tres rapide à écrire\n",
    "- des identifiants (hash) sont utilisés pour tout les attributs sous forme de stirng, pour réduire l'utilisation mémoire et améliorer l'efficacité des calculs (comparaison, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And 88 CCONJ : coordinating conjunction\n",
      "in 84 ADP : adposition\n",
      "early 83 ADJ : adjective\n",
      "2016 92 NUM : numeral\n",
      ", 96 PUNCT : punctuation\n",
      "hackers 91 NOUN : noun\n",
      "at 84 ADP : adposition\n",
      "AnonSec 95 PROPN : proper noun\n",
      "claimed 99 VERB : verb\n",
      "to 93 PART : particle\n",
      "have 99 VERB : verb\n",
      "developed 99 VERB : verb\n",
      "a 89 DET : determiner\n",
      "method 91 NOUN : noun\n",
      "for 84 ADP : adposition\n",
      "gaining 99 VERB : verb\n",
      "partial 83 ADJ : adjective\n",
      "control 91 NOUN : noun\n",
      "over 84 ADP : adposition\n",
      "one 92 NUM : numeral\n",
      "of 84 ADP : adposition\n",
      "the 89 DET : determiner\n",
      "Global 95 PROPN : proper noun\n",
      "Hawk 95 PROPN : proper noun\n",
      "drones 91 NOUN : noun\n",
      "used 99 VERB : verb\n",
      "by 84 ADP : adposition\n",
      "NASA 95 PROPN : proper noun\n",
      ". 96 PUNCT : punctuation\n",
      "Meanwhile 85 ADV : adverb\n",
      ", 96 PUNCT : punctuation\n",
      "researchers 91 NOUN : noun\n",
      "at 84 ADP : adposition\n",
      "the 89 DET : determiner\n",
      "Singapore 95 PROPN : proper noun\n",
      "University 95 PROPN : proper noun\n",
      "of 84 ADP : adposition\n",
      "Technology 95 PROPN : proper noun\n",
      "and 88 CCONJ : coordinating conjunction\n",
      "Design 95 PROPN : proper noun\n",
      "have 99 VERB : verb\n",
      "devised 99 VERB : verb\n",
      "a 89 DET : determiner\n",
      "technique 91 NOUN : noun\n",
      "for 84 ADP : adposition\n",
      "using 99 VERB : verb\n",
      "drones 91 NOUN : noun\n",
      "to 93 PART : particle\n",
      "orchestrate 99 VERB : verb\n",
      "MitM 91 NOUN : noun\n",
      "attacks 91 NOUN : noun\n",
      "which 83 ADJ : adjective\n",
      "exploit 99 VERB : verb\n",
      "wireless 83 ADJ : adjective\n",
      "printing 99 VERB : verb\n",
      "networks 91 NOUN : noun\n",
      "on 84 ADP : adposition\n",
      "a 89 DET : determiner\n",
      "corporate 83 ADJ : adjective\n",
      "scale 91 NOUN : noun\n",
      ", 96 PUNCT : punctuation\n",
      "to 93 PART : particle\n",
      "eavesdrop 99 VERB : verb\n",
      "on 84 ADP : adposition\n",
      "print 91 NOUN : noun\n",
      "jobs 91 NOUN : noun\n",
      ". 96 PUNCT : punctuation\n",
      "The 89 DET : determiner\n",
      "Flip 95 PROPN : proper noun\n",
      "Side 91 NOUN : noun\n",
      ": 96 PUNCT : punctuation\n",
      "Counter 91 NOUN : noun\n",
      "- 96 PUNCT : punctuation\n",
      "attack\\nAs 91 NOUN : noun\n",
      "with 84 ADP : adposition\n",
      "so 85 ADV : adverb\n",
      "many 83 ADJ : adjective\n",
      "potential 83 ADJ : adjective\n",
      "attackvectors 91 NOUN : noun\n",
      ", 96 PUNCT : punctuation\n",
      "unmanned 83 ADJ : adjective\n",
      "aerial 83 ADJ : adjective\n",
      "vehicles 91 NOUN : noun\n",
      "may 99 VERB : verb\n",
      "feature 99 VERB : verb\n",
      "as 84 ADP : adposition\n",
      "a 89 DET : determiner\n",
      "weapon 91 NOUN : noun\n",
      "in 84 ADP : adposition\n",
      "the 89 DET : determiner\n",
      "armory 91 NOUN : noun\n",
      "of 84 ADP : adposition\n",
      "both 89 DET : determiner\n",
      "defenders 91 NOUN : noun\n",
      "and 88 CCONJ : coordinating conjunction\n",
      "attackers 91 NOUN : noun\n",
      ". 96 PUNCT : punctuation\n",
      "For 84 ADP : adposition\n",
      "instance 91 NOUN : noun\n",
      ", 96 PUNCT : punctuation\n",
      "the 89 DET : determiner\n",
      "MalDrone 95 PROPN : proper noun\n",
      "backdoor 91 NOUN : noun\n",
      "malware 91 NOUN : noun\n",
      "kit 91 NOUN : noun\n",
      "has 99 VERB : verb\n",
      "been 99 VERB : verb\n",
      "developed 99 VERB : verb\n",
      "as 84 ADP : adposition\n",
      "a 89 DET : determiner\n",
      "universal 83 ADJ : adjective\n",
      "hack 91 NOUN : noun\n",
      ", 96 PUNCT : punctuation\n",
      "applicable 83 ADJ : adjective\n",
      "to 84 ADP : adposition\n",
      "all 89 DET : determiner\n",
      "makes 91 NOUN : noun\n",
      "and 88 CCONJ : coordinating conjunction\n",
      "models 91 NOUN : noun\n",
      "of 84 ADP : adposition\n",
      "UAV 95 PROPN : proper noun\n",
      ". 96 PUNCT : punctuation\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word, word.pos, word.pos_, \":\",spacy.explain(word.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- syntaxe rapide\n",
    "- POS pour Part Of Speech et non pas position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early 2016 DATE  :  Absolute or relative dates or periods\n",
      "AnonSec ORG  :  Companies, agencies, institutions, etc.\n",
      "one CARDINAL  :  Numerals that do not fall under another type\n",
      "Global Hawk ORG  :  Companies, agencies, institutions, etc.\n",
      "NASA ORG  :  Companies, agencies, institutions, etc.\n",
      "the Singapore University of Technology and Design ORG  :  Companies, agencies, institutions, etc.\n",
      "The Flip Side PRODUCT  :  Objects, vehicles, foods, etc. (not services)\n",
      "Counter-attack\\nAs PERSON  :  People, including fictional\n",
      "MalDrone ORG  :  Companies, agencies, institutions, etc.\n",
      "UAV ORG  :  Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text,entity.label_,\" : \",str(spacy.explain(entity.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Flip Side: Counter-attack\\nAs est détécté comme WORK_OF_ART : pourquoi pas ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEPENDENDY EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And : type:  cc , fils : []\n",
      "in : type:  prep , fils : [2016]\n",
      "early : type:  amod , fils : []\n",
      "2016 : type:  pobj , fils : [early]\n",
      ", : type:  punct , fils : []\n",
      "hackers : type:  nsubj , fils : [at]\n",
      "at : type:  prep , fils : [AnonSec]\n",
      "AnonSec : type:  pobj , fils : []\n",
      "claimed : type:  ROOT , fils : [And, in, ,, hackers, developed, .]\n",
      "to : type:  aux , fils : []\n",
      "have : type:  aux , fils : []\n",
      "developed : type:  xcomp , fils : [to, have, method]\n",
      "a : type:  det , fils : []\n",
      "method : type:  dobj , fils : [a, for]\n",
      "for : type:  prep , fils : [gaining]\n",
      "gaining : type:  pcomp , fils : [control, over]\n",
      "partial : type:  amod , fils : []\n",
      "control : type:  dobj , fils : [partial]\n",
      "over : type:  prep , fils : [one]\n",
      "one : type:  pobj , fils : [of]\n",
      "of : type:  prep , fils : [drones]\n",
      "the : type:  det , fils : []\n",
      "Global : type:  compound , fils : []\n",
      "Hawk : type:  compound , fils : [Global]\n",
      "drones : type:  pobj , fils : [the, Hawk, used]\n",
      "used : type:  acl , fils : [by]\n",
      "by : type:  agent , fils : [NASA]\n",
      "NASA : type:  pobj , fils : []\n",
      ". : type:  punct , fils : []\n",
      "Meanwhile : type:  advmod , fils : []\n",
      ", : type:  punct , fils : []\n",
      "researchers : type:  nsubj , fils : [at]\n",
      "at : type:  prep , fils : [University]\n",
      "the : type:  det , fils : []\n",
      "Singapore : type:  compound , fils : []\n",
      "University : type:  pobj , fils : [the, Singapore, of]\n",
      "of : type:  prep , fils : [Technology]\n",
      "Technology : type:  pobj , fils : [and, Design]\n",
      "and : type:  cc , fils : []\n",
      "Design : type:  conj , fils : []\n",
      "have : type:  aux , fils : []\n",
      "devised : type:  ROOT , fils : [Meanwhile, ,, researchers, have, technique, .]\n",
      "a : type:  det , fils : []\n",
      "technique : type:  dobj , fils : [a, for]\n",
      "for : type:  prep , fils : [using]\n",
      "using : type:  pcomp , fils : [drones, orchestrate]\n",
      "drones : type:  dobj , fils : []\n",
      "to : type:  aux , fils : []\n",
      "orchestrate : type:  xcomp , fils : [to, attacks]\n",
      "MitM : type:  amod , fils : []\n",
      "attacks : type:  dobj , fils : [MitM, exploit]\n",
      "which : type:  nsubj , fils : []\n",
      "exploit : type:  relcl , fils : [which, networks, on, ,, eavesdrop]\n",
      "wireless : type:  amod , fils : []\n",
      "printing : type:  compound , fils : []\n",
      "networks : type:  dobj , fils : [wireless, printing]\n",
      "on : type:  prep , fils : [scale]\n",
      "a : type:  det , fils : []\n",
      "corporate : type:  amod , fils : []\n",
      "scale : type:  pobj , fils : [a, corporate]\n",
      ", : type:  punct , fils : []\n",
      "to : type:  aux , fils : []\n",
      "eavesdrop : type:  advcl , fils : [to, on]\n",
      "on : type:  prep , fils : [jobs]\n",
      "print : type:  compound , fils : []\n",
      "jobs : type:  pobj , fils : [print]\n",
      ". : type:  punct , fils : []\n",
      "The : type:  det , fils : []\n",
      "Flip : type:  compound , fils : []\n",
      "Side : type:  nsubj , fils : [The, Flip, :, attack\\nAs]\n",
      ": : type:  punct , fils : []\n",
      "Counter : type:  compound , fils : []\n",
      "- : type:  punct , fils : []\n",
      "attack\\nAs : type:  appos , fils : [Counter, -, with]\n",
      "with : type:  prep , fils : [attackvectors]\n",
      "so : type:  advmod , fils : []\n",
      "many : type:  amod , fils : [so]\n",
      "potential : type:  amod , fils : []\n",
      "attackvectors : type:  pobj , fils : [many, potential]\n",
      ", : type:  punct , fils : []\n",
      "unmanned : type:  amod , fils : []\n",
      "aerial : type:  amod , fils : []\n",
      "vehicles : type:  nsubj , fils : [unmanned, aerial]\n",
      "may : type:  aux , fils : []\n",
      "feature : type:  ROOT , fils : [Side, ,, vehicles, may, as, .]\n",
      "as : type:  prep , fils : [weapon]\n",
      "a : type:  det , fils : []\n",
      "weapon : type:  pobj , fils : [a, in]\n",
      "in : type:  prep , fils : [armory]\n",
      "the : type:  det , fils : []\n",
      "armory : type:  pobj , fils : [the, of]\n",
      "of : type:  prep , fils : [defenders]\n",
      "both : type:  det , fils : []\n",
      "defenders : type:  pobj , fils : [both, and, attackers]\n",
      "and : type:  cc , fils : []\n",
      "attackers : type:  conj , fils : []\n",
      ". : type:  punct , fils : []\n",
      "For : type:  prep , fils : [instance]\n",
      "instance : type:  pobj , fils : []\n",
      ", : type:  punct , fils : []\n",
      "the : type:  det , fils : []\n",
      "MalDrone : type:  nummod , fils : [the]\n",
      "backdoor : type:  amod , fils : []\n",
      "malware : type:  amod , fils : []\n",
      "kit : type:  nsubjpass , fils : [MalDrone, backdoor, malware]\n",
      "has : type:  aux , fils : []\n",
      "been : type:  auxpass , fils : []\n",
      "developed : type:  ROOT , fils : [For, ,, kit, has, been, as, .]\n",
      "as : type:  prep , fils : [hack]\n",
      "a : type:  det , fils : []\n",
      "universal : type:  amod , fils : []\n",
      "hack : type:  pobj , fils : [a, universal, ,, applicable]\n",
      ", : type:  punct , fils : []\n",
      "applicable : type:  amod , fils : [to]\n",
      "to : type:  prep , fils : [makes]\n",
      "all : type:  det , fils : []\n",
      "makes : type:  pobj , fils : [all, and, models]\n",
      "and : type:  cc , fils : []\n",
      "models : type:  conj , fils : [of]\n",
      "of : type:  prep , fils : [UAV]\n",
      "UAV : type:  pobj , fils : []\n",
      ". : type:  punct , fils : []\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word, \": type: \",word.dep_,\", fils :\",[child for child in word.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORDNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- non présent dans spacy, une bibliotheque python existe pour faire le lien, spacy_wordnet.\n",
    "- utiliser nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiser avec spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utiliser displacy.serve(nlp('un texte'),...) permet de visualiser via un serveur http dédié, en dehors d'un notebook par exemple\n",
    "- l'option distance est rapidement necessaire (testez sans et vous verrez)\n",
    "- des options permettant un rendu plus compact et personnalisable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">And in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    early 2016\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", hackers at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    AnonSec\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " claimed to have developed a method for gaining partial control over \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Global Hawk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " drones used by \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    NASA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". Meanwhile, researchers at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Singapore University of Technology and Design\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " have devised a technique for using drones to orchestrate MitM attacks which exploit wireless printing networks on a corporate scale, to eavesdrop on print jobs. \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    The Flip Side\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       ": \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Counter-attack\\nAs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " with so many potential attackvectors, unmanned aerial vehicles may feature as a weapon in the armory of both defenders and attackers.For instance, the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    MalDrone\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " backdoor malware kit has been developed as a universal hack, applicable to all makes and models of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UAV\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'arbre de dépendance peut être exporté en svg (format d'image vectoriel)\n",
    "- displaCy fonctionne avec du html pour générer ses figures, et ce html peut etre exporté pour sauvegarder/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
